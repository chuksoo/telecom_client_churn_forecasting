{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telecom client churn forecast using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interconnect telecom would like to be able to forecast their churn of clients. If it's discovered that a user is planning to leave, they will be offered promotional codes and special plan options. Interconnect's marketing team has collected some of their clientele's personal data, including information about their plans and contracts.\n",
    "\n",
    "### Interconnect's services\n",
    "\n",
    "Interconnect mainly provides two types of services:\n",
    "\n",
    "1. Landline communication. The telephone can be connected to several lines simultaneously.\n",
    "2. Internet. The network can be set up via a telephone line (DSL, *digital subscriber line*) or through a fiber optic cable.\n",
    "\n",
    "Some other services the company provides include:\n",
    "\n",
    "- Internet security: antivirus software (*DeviceProtection*) and a malicious website blocker (*OnlineSecurity*)\n",
    "- A dedicated technical support line (*TechSupport*)\n",
    "- Cloud file storage and data backup (*OnlineBackup*)\n",
    "- TV streaming (*StreamingTV*) and a movie directory (*StreamingMovies*)\n",
    "\n",
    "The clients can choose either a monthly payment or sign a 1- or 2-year contract. They can use various payment methods and receive an electronic invoice after a transaction.\n",
    "\n",
    "### Data Description\n",
    "\n",
    "The data consists of files obtained from different sources:\n",
    "\n",
    "- `contract.csv` — contract information\n",
    "- `personal.csv` — the client's personal data\n",
    "- `internet.csv` — information about Internet services\n",
    "- `phone.csv` — information about telephone services\n",
    "\n",
    "In each file, the column `customerID` contains a unique code assigned to each client.\n",
    "\n",
    "The contract information is valid as of February 1, 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "The objectives of this project is to:\n",
    "- Build a machine learning model to forecast Interconnect telecom's client churn\n",
    "- Apply exploratory data analysis in determining whether special promotional services and plan options will discourage client churn\n",
    "- Analyze the speed and quality of prediction, time required for training, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    " # Table of contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ol>\n",
    "        <li><a href=\"#open_the_data\">Open the data file and study the general information</a></li>\n",
    "        <li><a href=\"#data_preprocessing\">Data Preprocessing</a></li>\n",
    "        <li><a href=\"#data_visualization\">Exploratory Data Analysis</a></li>\n",
    "        <li><a href=\"#model_training\">Model Training</a></li>\n",
    "        <li><a href=\"#model_testing\">Model Testing</a></li>\n",
    "        <li><a href=\"#model_analysis\">Model Analysis</a></li>\n",
    "        <li><a href=\"#overall_conclusion\">Overall Conclusion</a></li>\n",
    "    </ol>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"open_the_data\">\n",
    "    <h2>Open the data and study the general information</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We require the following libraries: *pandas* and *numpy* for data preprocessing and manipulation, *matplotlib* and *seaborn* for data visualization, *scikit-learn* for building our machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# seaborn for statistical data visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# import module for splitting and cross-validation using gridsearch\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# import modules for preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pd.options.mode.chained_assignment = None # to avoid SettingWithCopyWarning after scaling\n",
    "\n",
    "# import machine learning module from the sklearn library\n",
    "from sklearn.dummy import DummyClassifier # import dummy classifier\n",
    "from sklearn.tree import DecisionTreeClassifier # import decision tree classifier\n",
    "from sklearn.linear_model import LogisticRegression # import logistic regression \n",
    "from sklearn.ensemble import RandomForestClassifier # import random forest algorithm\n",
    "from catboost import CatBoostClassifier # import catboost classifier\n",
    "from lightgbm import LGBMClassifier # import lightgbm classifier\n",
    "from xgboost import XGBClassifier # import xgboost classifier\n",
    "\n",
    "# import metrics for sanity check on model\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Project libraries has been successfully been imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "try:\n",
    "    contract_data = pd.read_csv('C:/Users/hotty/Desktop/Practicum by Yandex/Projects/Final Project/final_provider/contract.csv')\n",
    "    internet_data = pd.read_csv('C:/Users/hotty/Desktop/Practicum by Yandex/Projects/Final Project/final_provider/internet.csv')\n",
    "    personal_data = pd.read_csv('C:/Users/hotty/Desktop/Practicum by Yandex/Projects/Final Project/final_provider/personal.csv')\n",
    "    phone_data = pd.read_csv('C:/Users/hotty/Desktop/Practicum by Yandex/Projects/Final Project/final_provider/phone.csv')\n",
    "except:\n",
    "    contract_data = pd.read_csv('https://code.s3.yandex.net/datasets/final_provider/contract.csv')\n",
    "    internet_data = pd.read_csv('https://code.s3.yandex.net/datasets/final_provider/internet.csv')\n",
    "    personal_data = pd.read_csv('https://code.s3.yandex.net/datasets/final_provider/personal.csv')\n",
    "    phone_data = pd.read_csv('https://code.s3.yandex.net/datasets/final_provider/phone.csv')\n",
    "print('Data has been read correctly!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine if columns in file have null values\n",
    "def get_percent_of_na(df, num):\n",
    "    count = 0\n",
    "    df = df.copy()\n",
    "    s = (df.isna().sum() / df.shape[0])\n",
    "    for column, percent in zip(s.index, s.values):\n",
    "        num_of_nulls = df[column].isna().sum()\n",
    "        if num_of_nulls == 0:\n",
    "            continue\n",
    "        else:\n",
    "            count += 1\n",
    "        print('Column {} has {:.{}%} percent of Nulls, and {} of nulls'.format(column, percent, num, num_of_nulls))\n",
    "    if count != 0:\n",
    "        print(\"\\033[1m\" + 'There are {} columns with NA.'.format(count) + \"\\033[0m\")\n",
    "    else:\n",
    "        print()\n",
    "        print(\"\\033[1m\" + 'There are no columns with NA.' + \"\\033[0m\")\n",
    "        \n",
    "# function to display general information about the dataset\n",
    "def get_info(df):\n",
    "    \"\"\"\n",
    "    This function uses the head(), info(), describe(), shape() and duplicated() \n",
    "    methods to display the general information about the dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\033[1m\" + '-'*100 + \"\\033[0m\")\n",
    "    print('Head:')\n",
    "    print()\n",
    "    display(df.head())\n",
    "    print('-'*100)\n",
    "    print('Info:')\n",
    "    print()\n",
    "    display(df.info())\n",
    "    print('-'*100)\n",
    "    print('Describe:')\n",
    "    print()\n",
    "    display(df.describe())\n",
    "    print('-'*100)\n",
    "    display(df.describe(include='object'))\n",
    "    print()\n",
    "    print('Columns with nulls:')\n",
    "    display(get_percent_of_na(df, 4))  # check this out\n",
    "    print('-'*100)\n",
    "    print('Shape:')\n",
    "    print(df.shape)\n",
    "    print('-'*100)\n",
    "    print('Duplicated:')\n",
    "    print(\"\\033[1m\" + 'We have {} duplicated rows.\\n'.format(df.duplicated().sum()) + \"\\033[0m\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study the general information about the contract dataset \n",
    "print('General information about the contract dataset')\n",
    "get_info(contract_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study the general information about the internet dataset \n",
    "print('General information about the internet dataset')\n",
    "get_info(internet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study the general information about the personal dataset \n",
    "print('General information about the personal dataset')\n",
    "get_info(personal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study the general information about the phone dataset \n",
    "print('General information about the phone dataset')\n",
    "get_info(phone_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "By looking at the general information about the data, we find that:\n",
    " - `contract_data` has 7043 rows and 8 columns with no missing values and no duplicated values\n",
    " - `internet_data` has 5517 rows and 8 columns with no missing values and no duplicated values\n",
    " - `personal_data` has 7043 rows and 5 columns with no missing values and no duplicated values\n",
    " - `phone_data` has 6361 rows and 2 columns with no missing values and no duplicated values\n",
    " \n",
    "We need to change datatype to the right datatype. For instance, in `contract_data`, we need to change `BeginDate`, `EndDate` to `Datetime` and `TotalCharges` to `float`. We also need to preprocess the data and generate new features for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"data_preprocessing\">\n",
    "    <h2>Data Preprocessing</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we would be wrangling the data. We would have to merge the dataset, replace column names, change datatypes and perform feature engineering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin to preprocess the data, we can merge all the individual datasets into one dataframe using the `merge()` function in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining datasets \n",
    "merged_df = pd.merge(contract_data, personal_data, on=\"customerID\")\n",
    "merged_df1 = pd.merge(merged_df, phone_data, on=\"customerID\")\n",
    "merged_df2 = pd.merge(merged_df1, internet_data, on=\"customerID\")\n",
    "merged_df2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create copy of dataset\n",
    "telecom_df = merged_df2.copy()\n",
    "telecom_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step in data preprocessing will be to replace columns names in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "telecom_df = telecom_df.rename(columns={'customerID': 'customer_id', 'BeginDate': 'begin_date', 'EndDate': 'end_date', 'Type': 'type',\n",
    "       'PaperlessBilling': 'paperless_billing', 'PaymentMethod': 'payment_method', 'MonthlyCharges': 'monthly_charges', 'TotalCharges': 'total_charges',\n",
    "       'gender': 'gender', 'SeniorCitizen': 'senior_citizen', 'Partner': 'partner', 'Dependents': 'dependents', 'MultipleLines': 'multiple_lines',\n",
    "       'InternetService': 'internet_service', 'OnlineSecurity': 'online_security', 'OnlineBackup': 'online_backup', 'DeviceProtection': 'device_protection',\n",
    "       'TechSupport': 'tech_support', 'StreamingTV': 'streaming_tv', 'StreamingMovies': 'streaming_movies'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We renamed column names so that the column names will be uniform. i.e., using snake case for improved readability. The `rename()` function in pandas is used to make these changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Datatypes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we change datatypes to the right format. For instance, `begin_date` and `end_date` will be changed to `Datetime`, `monthly_charges` and `total_charges` to `float32`, `senior_citizen` to `int32` datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to change data to the right type\n",
    "def change_datatype(df, cols, type_val):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(type_val)\n",
    "\n",
    "# create new end date feature\n",
    "list_value = []\n",
    "for value in telecom_df.end_date:\n",
    "    if value != 'No':\n",
    "        datetime_value = datetime.strptime(value, '%Y-%m-%d %H:%M:%S')\n",
    "        list_value.append(datetime_value)\n",
    "    else:\n",
    "        list_value.append(datetime.now())\n",
    "EndDate_value = pd.to_datetime(list_value)\n",
    "telecom_df.insert(3, 'end_date_value', EndDate_value)\n",
    "\n",
    "# prepare TotalChargers \n",
    "telecom_df.loc[telecom_df['total_charges'].isin([' ']),'total_charges'] = 0\n",
    "\n",
    "# change datatypes\n",
    "change_datatype(telecom_df, ['begin_date'], 'datetime64[ns]')\n",
    "change_datatype(telecom_df, ['monthly_charges', 'total_charges'], 'float32')\n",
    "change_datatype(telecom_df, ['senior_citizen'], 'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data information\n",
    "telecom_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will create new features such as length of tenure `tenure`, the target end date `exited` denoted as 0 for no churn and 1 for churn, `service_count` denoting the number of products (or services) the customer is currently using, `has_crcard` indicating the customer uses credit card for payment, `year`, `month` and `dayofweek` the customer began using Interconnect's services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change date type to datetime and split into day, month and year\n",
    "def new_date_features(df):\n",
    "    columns = df.columns.tolist()\n",
    "    idx = [columns.index(x) for x in columns if 'begin_date' in x][0]\n",
    "    \n",
    "    df[columns[idx]] = pd.to_datetime(df[columns[idx]])\n",
    "    df['dayofweek'] = df[columns[idx]].dt.day_name()\n",
    "    df['month'] = df[columns[idx]].dt.month_name()\n",
    "    df['year'] = df[columns[idx]].dt.year\n",
    "    return df;    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new features to data\n",
    "new_date_features(telecom_df)\n",
    "telecom_df['tenure'] = telecom_df['end_date_value'].dt.year - telecom_df['begin_date'].dt.year\n",
    "telecom_df['has_crcard'] = [1 if x == 'Credit card (automatic)' else 0 for x in telecom_df['payment_method']]\n",
    "telecom_df['exited'] = [1 if x != 'No' else 0 for x in telecom_df['end_date']]\n",
    "telecom_df['service_count'] = [x.count('Yes') for x in zip(telecom_df['online_security'], telecom_df['online_backup'], telecom_df['device_protection'], \n",
    "                                                           telecom_df['tech_support'], telecom_df['streaming_tv'], telecom_df['streaming_movies'])]\n",
    "change_datatype(telecom_df, ['year', 'tenure', 'has_crcard', 'exited', 'service_count'], 'int32') # reduce memory usage by changing datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe\n",
    "telecom_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using list comprehension, we have been able to generate new features that are relevant to the dataset. We engineered features such as `tenure`, `exited`, `service_count`, `has_crcard`, `year`, `month` and `dayofweek`. All these features will help our machine learning model to avoid bias when building the model. We also don't want to have too many features to avoid high variance - when the model is too complex that it doesn't generalize well to the test data or it *overfits* the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck dataframe information\n",
    "telecom_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "We carried out data preprocessing in order to merge the datasets, replace column names, change datatype, and generate new features for machine learning. We applied the SQL-flavored merging with pandas to merge the dataset. We renamed column names for improved readability, and change datatypes to the right format in order to reduce memory requirement during computation. We performed feature engineering in order to generate new features that will be helpful in exploring the data and useful for our machine learning process. Now the data is ready for further exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"data_visualization\">\n",
    "    <h2>Exploratory Data Analysis</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In exploring the data, we would be asking various questions that need answers in order to uncover or understand the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What payment type and payment methods are unique to Interconnect's customer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_payment_type_count = (telecom_df['type'].value_counts() / telecom_df['type'].value_counts().sum() * 100).tolist()   \n",
    "\n",
    "# unique payment type\n",
    "unique_payment_type = telecom_df['type'].value_counts().reset_index().rename(columns={'index': 'type', 'type': 'unique count'})\n",
    "unique_payment_type['percentage split (%)'] = ['{:.2f}'.format(x) for x in unique_payment_type_count]\n",
    "unique_payment_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_payment_method_count = (telecom_df['payment_method'].value_counts() / telecom_df['payment_method'].value_counts().sum() * 100).tolist()\n",
    "\n",
    "# unique payment method\n",
    "unique_payment_method = telecom_df['payment_method'].value_counts().reset_index().rename(columns={'index': 'payment method', 'payment_method': 'count'})\n",
    "unique_payment_method['% payment split'] = ['{:.2f}'.format(x) for x in unique_payment_method_count]\n",
    "unique_payment_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis above, we see that most Interconnect customers prefer month-to-month payment with 61% of payment done using this medium. Also, electronic check was frequently used to make payment amongst the payment method available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we deduce a relationship between payment method and total charges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total charges grouped by payment method\n",
    "total_charges_grouped = telecom_df.groupby('payment_method', as_index=False).agg({'total_charges': 'sum'}).sort_values(\n",
    "    by='total_charges', ascending=False, ignore_index=True)\n",
    "total_charges_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can agree that customers making payment with electronic check had the highest total charges. With this knowledge, marketing team can channel more marketing campaign to make these set of customers use more services. Customers who mail-in check on the other hand had the lowest total charges. Here, marketing team can device new marketing campaign to make the these sets of customers to embrace either the bank transfer method or the electronic check method. If we can get all the customers sending in mail-in checks to use the electronic check, then we would have more total customer charges which translate to more revenue for Interconnect telecom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we deduce a relationship between payment type and total monthly charges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total monthly charges grouped by payment type\n",
    "(telecom_df.groupby('type', as_index=False)\n",
    "     .agg({'monthly_charges': 'sum', 'total_charges': 'sum'})\n",
    "     .sort_values(by='total_charges', ascending=False, ignore_index=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that customers on a two-year contract bring in more total revenue than customers on a one year contract. The marketing team at Interconnect can introduce more two year contract plan to entice more customers to sign up for a two year contract. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Services count by contract type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# services count grouped by contract type\n",
    "(telecom_df.groupby('type', as_index=False)\n",
    "     .agg({'service_count': 'sum'})\n",
    "     .sort_values(by='service_count', ascending=False, ignore_index=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that customers on a month-to-month contract use more services than customers on a one year contract. This knowledge would inform advertisement campaigns and marketing efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What gender have the most total charges and service count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total charges grouped by gender\n",
    "gender_charges = telecom_df.groupby('gender', as_index=False).agg({'total_charges': 'sum', 'service_count': 'sum'}).sort_values(by='total_charges', ascending=False, ignore_index=True)\n",
    "change_datatype(gender_charges, ['total_charges'], 'int32')\n",
    "gender_charges['percent_total_charges'] = gender_charges['total_charges'] / sum(gender_charges['total_charges']) * 100\n",
    "gender_charges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that the female gender contributed almost as much as the male to the total charges and Interconnect's revenue. In addition, the female used more services than the male folks even though this did not translate to increased revenue or total charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot seaborn barplot\n",
    "def plot_snsbar(df, x, y, title):\n",
    "    xlabel = str(x.replace('_', ' ').capitalize())\n",
    "    ylabel = str(y.replace('_', ' ').capitalize())\n",
    "    # create grouped data\n",
    "    data = df.groupby([x])[y].count().sort_values(ascending=False).reset_index()\n",
    "    fig, ax=plt.subplots(figsize=(10,6))\n",
    "    ax = sns.barplot(x = x, y = y, data=data)\n",
    "    ax.set_title(title, fontdict={'size':12})\n",
    "    ax.set_ylabel(ylabel, fontsize = 10)\n",
    "    ax.set_xlabel(xlabel, fontsize = 10)\n",
    "    ax.set_xticklabels(data[x], rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check correlation in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix of features\n",
    "plt.figure(figsize=(8, 6))\n",
    "corrMatrix = telecom_df.corr()\n",
    "sns.heatmap(corrMatrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Plot for certain features')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of tenure and churn\n",
    "telecom_df.plot(\n",
    "    x='tenure', y='exited', title = 'Hexagonal binning plot for correlation of tenure and churn', \n",
    "    kind='hexbin', gridsize=20, figsize=(8, 6), sharex=False, grid=True\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the correlation plot, we can see that there is a strong negative correlation between `tenure` and `exited` (or churn). Customers with less tenure are more likely to churn than well-established customers. To prevent churn, Interconnect telecom must introduce promotion and increase service offering in other to keep customers for longer. We see that the longer a customer stays with Interconnect telecoms, the less likely the customers churn. Whether a customer made subscription on a month-to-month basis did not really affect churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of dependents on customer churn\n",
    "telecom_df['has_dependents'] = [1 if x != 'No' else 0 for x in telecom_df['dependents']]\n",
    "telecom_df.plot(\n",
    "    x='has_dependents', y='exited', title = 'Hexagonal binning plot for correlation of dependents and customer churn', \n",
    "    kind='hexbin', gridsize=20, figsize=(8, 6), sharex=False, grid=True\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that more customers without dependents stayed longer with Interconnect telecoms than customers with dependent. This is reasonable because having dependent tends to increase your average expenses. It would make sense for Interconnect to target customers with less dependents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can contract type affect customer churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect of contract type on customer churn\n",
    "contract_type_percent = telecom_df.groupby('type', as_index=False).agg({'exited': 'sum'}).sort_values(by='exited', ascending=False, ignore_index=True)\n",
    "contract_type_effect = (telecom_df['type'].value_counts() / telecom_df['type'].value_counts().sum() * 100).tolist()\n",
    "contract_type_percent['% exit percent'] = ['{:.2f}'.format(x) for x in contract_type_effect]\n",
    "contract_type_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of contract type on customer churn\n",
    "plot_snsbar(telecom_df, 'type', 'exited', 'Plot of contract type on customer churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualized the contract type to see whether customers with shorter contract churn faster than customers with year-long contracts. Our analysis shows that customers with two-year long contract tends to stay longer while customers on a month-to-month contract type churned faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the top 5 services offered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a copy of the dataframe to use for encoding\n",
    "telecom_df_encode = telecom_df.copy()\n",
    "\n",
    "# encoding services offered \n",
    "online_security = {'online_security':{'Yes': 1, 'No': 0}}\n",
    "online_backup = {'online_backup':{'Yes': 1, 'No': 0}}\n",
    "device_protection = {'device_protection':{'Yes': 1, 'No': 0}}\n",
    "tech_support = {'tech_support':{'Yes': 1, 'No': 0}}\n",
    "streaming_tv = {'streaming_tv':{'Yes': 1, 'No': 0}}\n",
    "streaming_movies = {'streaming_movies':{'Yes': 1, 'No': 0}}\n",
    "\n",
    "telecom_df_encode.replace(online_security, inplace =True)\n",
    "telecom_df_encode.replace(online_backup, inplace =True)\n",
    "telecom_df_encode.replace(device_protection, inplace =True)\n",
    "telecom_df_encode.replace(tech_support, inplace =True)\n",
    "telecom_df_encode.replace(streaming_tv, inplace =True)\n",
    "telecom_df_encode.replace(streaming_movies, inplace =True)\n",
    "\n",
    "telecom_services_data = telecom_df_encode[['online_security', 'online_backup', 'device_protection', 'tech_support', 'streaming_tv', 'streaming_movies', 'exited']]\n",
    "telecom_services_data = telecom_services_data.transpose()\n",
    "telecom_services_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting dataframe showing services and percentage count \n",
    "telecom_services_data['count'] = telecom_services_data.sum(axis=1)\n",
    "telecom_services_df = telecom_services_data.reset_index(inplace=False)\n",
    "telecom_services_df = telecom_services_df[['index', 'count']].rename(columns={'index': 'services'})\n",
    "telecom_services_df['% service offered']  = telecom_services_df['count'] / telecom_services_df['count'].sum() * 100\n",
    "telecom_services = telecom_services_df.copy()\n",
    "telecom_services.sort_values('% service offered', axis = 0, ascending = False, inplace = True, ignore_index=True)\n",
    "telecom_services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of top 5 Interconnect service by count \n",
    "telecom_services_pie = telecom_services.head(5)\n",
    "(telecom_services_pie.set_index('services').plot(y='% service offered', kind='pie', \n",
    "                      title = 'Pie chart showing relative size of the five popular services', \n",
    "                      figsize=(8, 8), autopct='%1.1f%%', shadow=True)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot of top 5 services offered by Interconnect telecoms, we can see that `streaming_tv`, `streaming_videos` are in high demand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can number of services offered affect customer churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of service count on customer churn\n",
    "plot_snsbar(telecom_df, 'service_count', 'exited', 'Plot of service count on customer churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The service count has very weak correlation with customer churn. From the plot, we see that customers using between 5 and 6 services churned less. This indicates that having customers to sign up for more than 5 services at a time may likely prevent customer churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about the day of the week effect on customer churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to determine day of the week effect on customer churn\n",
    "plot_snsbar(telecom_df, 'dayofweek', 'exited', 'Plot of day of the week effect on customer churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most churn occured during the weekend. With this knowledge, Interconnect telecom can introduce incentives and weekend service bonuses to ensure customers do not disconnect their services over the weekend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What months had the most churn and how can it be prevented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to determine months with the most churn\n",
    "plot_snsbar(telecom_df, 'month', 'exited', 'Plot of months with the most customer churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, the months of February, September, November and December had the most churn. With this understanding, Interconnect telecoms can introduce several bonuses, free service plans, free movie streaming services or discounted TV streaming services for six months starting from September to February. This will prevent customer churn during those period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "We can conclude the following from the exploratory data analysis done:\n",
    " - Most of Interconnect customers prefer month-to-month payment with 61% of payment done using month-to-month\n",
    " - Payment made with electronic check had the highest total charges and thus will bring in the most revenue\n",
    " - Customers on a two-year contract have the highest total charges and bring in more total revenue than customers on a one year contract. \n",
    " - Customers on a two-year contract churn less than other contract type.\n",
    " - Customers with more than 5 services at a time churn less \n",
    " - Most churn occured at weekends.\n",
    " \n",
    " \n",
    "**Action plan:**\n",
    " - The marketing team at Interconnect can introduce more two year contract plan to entice more customers to sign up for a two year contract.\n",
    " - Targeted marketing campaigns and promotional events should be done to promote the two-year plan to Interconnects customers\n",
    " - Customers should be encouraged to make payment using electronic check. This will increase Interconnect's revenue.\n",
    " - Incentivize services with serveral promos to induce more customers signing up for more services at a time.\n",
    " - Introduce serveral bonuses, free service plans, free streaming services or discounted TV streaming services for six months starting from September to February to prevent churn.\n",
    " - Special promotional events and services options should be introduced towards the end of the week to discourage client churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"model_training\">\n",
    "    <h2>Model Training</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we would train different models. We would be training a couple of tree-based models, gradient-boosted model and leaf-based model. The primary metric we chose to evaluate the model is AUC-ROC. The secondary metric is accuracy. AUC computes the area under the curve and the objective is to **maximize** this area. Accuracy tells us how often the classifier is correct and the objective is to **maximize** accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform feature engineering to encode all categorical features to numeric. Encoding features makes them useful for machine learning. We would be applying one-hot encoding, target encoding and ordinal encoding depending on the machine learning algorithm. We would be training the following models:\n",
    "\n",
    "| Model type | Model | Encoding type | Highlight | Cons |\n",
    "|:--- |:----|:---:|:---:| :--- |\n",
    "| Statistical based| Logistic regression | label encoding | Less prone to over-fitting | Can overfit in high dimensional datasets |\n",
    "| Tree-based | Decision Tree | label encoding | Prone to errors |    |\n",
    "|            | Random Forest | label encoding | Better than DT |     |\n",
    "| Leaf-based | Catboost      | No encoding    | Fastest algo  |      |\n",
    "| Gradient boosted | XGBoost | One-hot encoding | Pretty fast |      |\n",
    "| Gradient-boosted | LightGBM | One-hot encoding | Extremely fast |      |\n",
    "\n",
    "For tree based model such as decision tree and random forest, we make use of label encoding and one-hot encoding. For the XGBoost and LightGBM model, we make use of one-hot encoding. The XGBoost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. The CatBoost regressor has its own implementation for encoding of categorical features. In this case, we create a separate dataset without any encoding. Internally, catboost encodes the categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unimportant features\n",
    "df = telecom_df.drop(['customer_id', 'begin_date', 'end_date', 'end_date_value'], axis=1)\n",
    "\n",
    "# declare variables for target and features\n",
    "y = df.exited\n",
    "X = df.drop(['exited'], axis=1)\n",
    "\n",
    "# split data into 75% training and 25% testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create copy of initial split feature dataset\n",
    "features_train = X_train.copy()\n",
    "features_test = X_test.copy()\n",
    "\n",
    "# select numerical columns\n",
    "numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'int32']]\n",
    "\n",
    "# list of categorical variables\n",
    "s = (features_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "print('Categorical variables:')\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding features for machine learning\n",
    "\n",
    "# Approach 1: Ordinal Encoding\n",
    "# make a copy to avoid changing original data\n",
    "label__X_train = features_train.copy()\n",
    "label__X_test = features_test.copy()\n",
    "\n",
    "# apply ordinal encoder to each column with categorical data\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label__X_train[object_cols] = ordinal_encoder.fit_transform(features_train[object_cols])\n",
    "label__X_test[object_cols] = ordinal_encoder.transform(features_test[object_cols])\n",
    "\n",
    "# Approach 2: One-Hot Encoding\n",
    "# one-hot encoding of categorical features\n",
    "df_ohe = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# declare variables for target and features\n",
    "y_ohe = df_ohe.exited\n",
    "X_ohe = df_ohe.drop(['exited'], axis=1)\n",
    "\n",
    "# split data into 75% training and 25% testing sets\n",
    "X_train_ohe, X_test_ohe, y_train_ohe, y_test_ohe = train_test_split(X_ohe, y_ohe, test_size=0.25, random_state=12345)\n",
    "\n",
    "# numerical features\n",
    "numerical_cols = [cname for cname in X_train_ohe.columns if X_train_ohe[cname].dtype in ['float32', 'float64', 'int64', 'int32']]\n",
    "\n",
    "# features scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_ohe[numerical_cols])\n",
    "# transform the training set and the test set using transform()\n",
    "X_train_ohe[numerical_cols] = scaler.transform(X_train_ohe[numerical_cols])\n",
    "X_test_ohe[numerical_cols]  = scaler.transform(X_test_ohe[numerical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "We split the data into 75%  training and 25% testing sets. We applied both ordinal encoding and one-hot encoding to the features. We scaled the data after one-hot encoding using the standard scaler function. Next we are going to examine class imbalance and improve the model quality if class imbalance exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the balance of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate model evaluation metrics\n",
    "def print_model_evaluation(y_test, test_predictions):\n",
    "    print(\"\\033[1m\" + 'F1 score: ' + \"\\033[0m\", '{:.3f}'.format(f1_score(y_test, test_predictions)))\n",
    "    print(\"\\033[1m\" + 'Accuracy Score: ' + \"\\033[0m\", '{:.2%}'.format(accuracy_score(y_test, test_predictions)))\n",
    "    print(\"\\033[1m\" + 'Precision: ' + \"\\033[0m\", '{:.3f}'.format(precision_score(y_test, test_predictions)))\n",
    "    print(\"\\033[1m\" + 'Recall: ' + \"\\033[0m\", '{:.3f}'.format(recall_score(y_test, test_predictions)))\n",
    "    print(\"\\033[1m\" + 'Balanced Accuracy Score: ' + \"\\033[0m\", '{:.2%}'.format(balanced_accuracy_score(y_test, test_predictions)))\n",
    "    print(\"\\033[1m\" + 'AUC-ROC Score: ' + \"\\033[0m\", '{:.2%}'.format(roc_auc_score(y_test, test_predictions)))\n",
    "    print()\n",
    "    print(\"\\033[1m\" + 'Confusion Matrix' + \"\\033[0m\")\n",
    "    print('-'*50)\n",
    "    print(confusion_matrix(y_test, test_predictions))\n",
    "    print()\n",
    "    print(\"\\033[1m\" + 'Classification report' + \"\\033[0m\")\n",
    "    print('-'*50)\n",
    "    print(classification_report(y_test, test_predictions))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model using a dummy classifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(features_train, y_train)\n",
    "dummy_clf_test_predictions = dummy_clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate baseline model\n",
    "print_model_evaluation(y_test, dummy_clf_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model predicts the most frequent class in this case \"0\". Looking at the baseline model report, we can see that the accuracy is low and the AUC-ROC score is 50%. This is due to class imbalance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check with Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, y_train) # train the model \n",
    "test_predictions = pd.Series(model.predict(features_test))\n",
    "class_frequency = test_predictions.value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we would train different models. \n",
    "- We split the data into 80% training and 20% testing sets\n",
    "- We use AUC-ROC as our primary metric and accuracy as the secondary metric to predict customer churn\n",
    "- We apply encoding to categorical variables so they can be read by our machine learning models\n",
    "- We scale the data by applying standard scaler function to the features\n",
    "- We will use linear regresion model as our baseline model\n",
    "- We train different tree based model and gradient boosting model\n",
    "- We apply hyperparameter tuning to tune our different model and cross validation during sampling of data for machine learning\n",
    "- We choose the best performing models on the training accuracy and AUC-ROC metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"model_testing\">\n",
    "    <h2>Model Testing</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the best performing model, we evaluate on the test dataset\n",
    "- The best performing model is one that has the best accuracy on the training set\n",
    "- We plot a confusion matrix for the models performance on the test sets\n",
    "- We determine the best model's accuracy on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"model_analysis\">\n",
    "    <h2>Model Analysis</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"overall_conclusion\">\n",
    "    <h2>Overall Conclusion</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Based on chosen model, we can predict customer churn for Interconnect telecoms"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 893,
    "start_time": "2021-12-23T17:21:43.550Z"
   },
   {
    "duration": 873,
    "start_time": "2021-12-23T17:21:46.061Z"
   },
   {
    "duration": 3638,
    "start_time": "2021-12-23T17:21:48.445Z"
   },
   {
    "duration": 4,
    "start_time": "2021-12-23T17:22:54.386Z"
   },
   {
    "duration": 3519,
    "start_time": "2021-12-23T17:22:55.150Z"
   },
   {
    "duration": 500,
    "start_time": "2021-12-23T17:23:44.819Z"
   },
   {
    "duration": 462,
    "start_time": "2021-12-23T17:27:12.009Z"
   },
   {
    "duration": 485,
    "start_time": "2021-12-23T17:27:46.068Z"
   },
   {
    "duration": 1761,
    "start_time": "2022-01-01T06:34:34.775Z"
   },
   {
    "duration": 5806,
    "start_time": "2022-01-01T06:34:37.631Z"
   },
   {
    "duration": 13156,
    "start_time": "2022-01-01T06:37:22.431Z"
   },
   {
    "duration": 8637,
    "start_time": "2022-01-01T06:38:18.515Z"
   },
   {
    "duration": 6379,
    "start_time": "2022-01-01T06:39:51.910Z"
   },
   {
    "duration": 7592,
    "start_time": "2022-01-01T06:39:50.700Z"
   },
   {
    "duration": 6826,
    "start_time": "2022-01-01T06:50:02.185Z"
   },
   {
    "duration": 11,
    "start_time": "2022-01-01T06:50:41.486Z"
   },
   {
    "duration": 6930,
    "start_time": "2022-01-01T06:50:41.500Z"
   },
   {
    "duration": 10,
    "start_time": "2022-01-01T06:50:48.432Z"
   },
   {
    "duration": 140,
    "start_time": "2022-01-01T06:50:48.445Z"
   },
   {
    "duration": 141,
    "start_time": "2022-01-01T06:50:53.090Z"
   },
   {
    "duration": 95,
    "start_time": "2022-01-01T06:50:53.666Z"
   },
   {
    "duration": 72,
    "start_time": "2022-01-01T06:50:54.058Z"
   },
   {
    "duration": 61,
    "start_time": "2022-01-01T06:51:02.794Z"
   },
   {
    "duration": 15,
    "start_time": "2022-01-01T06:51:05.873Z"
   },
   {
    "duration": 9,
    "start_time": "2022-01-01T06:51:12.458Z"
   },
   {
    "duration": 59,
    "start_time": "2022-01-01T06:51:13.833Z"
   },
   {
    "duration": 16,
    "start_time": "2022-01-01T06:51:14.289Z"
   },
   {
    "duration": 6,
    "start_time": "2022-01-01T06:51:16.273Z"
   },
   {
    "duration": 38,
    "start_time": "2022-01-01T06:51:17.306Z"
   },
   {
    "duration": 34,
    "start_time": "2022-01-01T06:51:17.897Z"
   },
   {
    "duration": 17,
    "start_time": "2022-01-01T06:51:19.496Z"
   },
   {
    "duration": 23,
    "start_time": "2022-01-01T06:51:22.344Z"
   },
   {
    "duration": 23,
    "start_time": "2022-01-01T06:51:28.218Z"
   },
   {
    "duration": 382,
    "start_time": "2022-01-01T06:51:35.434Z"
   },
   {
    "duration": 16,
    "start_time": "2022-01-01T06:52:01.771Z"
   },
   {
    "duration": 16,
    "start_time": "2022-01-01T06:52:08.986Z"
   },
   {
    "duration": 361,
    "start_time": "2022-01-01T06:52:28.834Z"
   },
   {
    "duration": 372,
    "start_time": "2022-01-01T06:55:23.566Z"
   },
   {
    "duration": 392,
    "start_time": "2022-01-01T06:56:17.471Z"
   },
   {
    "duration": 362,
    "start_time": "2022-01-01T06:56:24.527Z"
   },
   {
    "duration": 120,
    "start_time": "2022-01-01T06:58:22.850Z"
   },
   {
    "duration": 602,
    "start_time": "2022-01-01T06:58:57.050Z"
   },
   {
    "duration": 396,
    "start_time": "2022-01-01T07:00:10.179Z"
   },
   {
    "duration": 16,
    "start_time": "2022-01-01T07:00:33.180Z"
   },
   {
    "duration": 15,
    "start_time": "2022-01-01T07:00:50.531Z"
   },
   {
    "duration": 374,
    "start_time": "2022-01-01T07:00:55.251Z"
   },
   {
    "duration": 16,
    "start_time": "2022-01-01T07:01:21.574Z"
   },
   {
    "duration": 18,
    "start_time": "2022-01-01T07:01:26.175Z"
   },
   {
    "duration": 16,
    "start_time": "2022-01-01T07:01:37.622Z"
   },
   {
    "duration": 384,
    "start_time": "2022-01-01T07:01:43.556Z"
   },
   {
    "duration": 22,
    "start_time": "2022-01-01T07:01:55.749Z"
   },
   {
    "duration": 1483,
    "start_time": "2022-01-01T07:02:13.086Z"
   },
   {
    "duration": 6463,
    "start_time": "2022-01-01T07:02:14.571Z"
   },
   {
    "duration": 11,
    "start_time": "2022-01-01T07:02:21.037Z"
   },
   {
    "duration": 150,
    "start_time": "2022-01-01T07:02:21.051Z"
   },
   {
    "duration": 190,
    "start_time": "2022-01-01T07:02:21.203Z"
   },
   {
    "duration": 118,
    "start_time": "2022-01-01T07:02:21.395Z"
   },
   {
    "duration": 97,
    "start_time": "2022-01-01T07:02:21.515Z"
   },
   {
    "duration": 94,
    "start_time": "2022-01-01T07:02:21.614Z"
   },
   {
    "duration": 14,
    "start_time": "2022-01-01T07:02:21.712Z"
   },
   {
    "duration": 30,
    "start_time": "2022-01-01T07:02:21.729Z"
   },
   {
    "duration": 63,
    "start_time": "2022-01-01T07:02:21.762Z"
   },
   {
    "duration": 37,
    "start_time": "2022-01-01T07:02:21.828Z"
   },
   {
    "duration": 6,
    "start_time": "2022-01-01T07:02:21.869Z"
   },
   {
    "duration": 41,
    "start_time": "2022-01-01T07:02:21.878Z"
   },
   {
    "duration": 65,
    "start_time": "2022-01-01T07:02:21.921Z"
   },
   {
    "duration": 26,
    "start_time": "2022-01-01T07:02:21.989Z"
   },
   {
    "duration": 51,
    "start_time": "2022-01-01T07:02:22.018Z"
   },
   {
    "duration": 24,
    "start_time": "2022-01-01T07:02:22.072Z"
   },
   {
    "duration": 27,
    "start_time": "2022-01-01T07:02:22.099Z"
   },
   {
    "duration": 41,
    "start_time": "2022-01-01T07:02:22.129Z"
   },
   {
    "duration": 17,
    "start_time": "2022-01-01T07:02:22.172Z"
   },
   {
    "duration": 21,
    "start_time": "2022-01-01T07:02:22.192Z"
   },
   {
    "duration": 1497,
    "start_time": "2022-01-01T07:35:42.256Z"
   },
   {
    "duration": 6687,
    "start_time": "2022-01-01T07:35:43.756Z"
   },
   {
    "duration": 12,
    "start_time": "2022-01-01T07:35:50.448Z"
   },
   {
    "duration": 165,
    "start_time": "2022-01-01T07:35:50.463Z"
   },
   {
    "duration": 181,
    "start_time": "2022-01-01T07:35:50.630Z"
   },
   {
    "duration": 110,
    "start_time": "2022-01-01T07:35:50.813Z"
   },
   {
    "duration": 139,
    "start_time": "2022-01-01T07:35:50.925Z"
   },
   {
    "duration": 66,
    "start_time": "2022-01-01T07:35:51.066Z"
   },
   {
    "duration": 36,
    "start_time": "2022-01-01T07:35:51.136Z"
   },
   {
    "duration": 10,
    "start_time": "2022-01-01T07:35:51.175Z"
   },
   {
    "duration": 87,
    "start_time": "2022-01-01T07:35:51.188Z"
   },
   {
    "duration": 14,
    "start_time": "2022-01-01T07:35:51.278Z"
   },
   {
    "duration": 6,
    "start_time": "2022-01-01T07:35:51.294Z"
   },
   {
    "duration": 61,
    "start_time": "2022-01-01T07:35:51.302Z"
   },
   {
    "duration": 33,
    "start_time": "2022-01-01T07:35:51.365Z"
   },
   {
    "duration": 20,
    "start_time": "2022-01-01T07:35:51.400Z"
   },
   {
    "duration": 49,
    "start_time": "2022-01-01T07:35:51.423Z"
   },
   {
    "duration": 21,
    "start_time": "2022-01-01T07:35:51.475Z"
   },
   {
    "duration": 16,
    "start_time": "2022-01-01T07:35:51.498Z"
   },
   {
    "duration": 49,
    "start_time": "2022-01-01T07:35:51.516Z"
   },
   {
    "duration": 17,
    "start_time": "2022-01-01T07:35:51.567Z"
   },
   {
    "duration": 22,
    "start_time": "2022-01-01T07:35:51.586Z"
   },
   {
    "duration": 6,
    "start_time": "2022-01-01T07:36:39.600Z"
   },
   {
    "duration": 7,
    "start_time": "2022-01-01T07:37:17.288Z"
   },
   {
    "duration": 9744,
    "start_time": "2022-01-01T07:39:29.660Z"
   },
   {
    "duration": 24,
    "start_time": "2022-01-01T07:39:52.444Z"
   },
   {
    "duration": 12,
    "start_time": "2022-01-01T07:40:30.381Z"
   },
   {
    "duration": 5,
    "start_time": "2022-01-01T07:40:34.797Z"
   },
   {
    "duration": 491,
    "start_time": "2022-01-01T07:44:44.185Z"
   },
   {
    "duration": 525,
    "start_time": "2022-01-01T07:45:48.634Z"
   },
   {
    "duration": 494,
    "start_time": "2022-01-01T07:46:10.523Z"
   },
   {
    "duration": 489,
    "start_time": "2022-01-01T07:46:36.732Z"
   },
   {
    "duration": 19,
    "start_time": "2022-01-01T07:50:30.394Z"
   },
   {
    "duration": 988,
    "start_time": "2022-01-01T07:57:06.447Z"
   },
   {
    "duration": 14,
    "start_time": "2022-01-01T08:02:01.836Z"
   },
   {
    "duration": 332,
    "start_time": "2022-01-01T08:04:42.778Z"
   },
   {
    "duration": 16,
    "start_time": "2022-01-01T08:09:35.959Z"
   },
   {
    "duration": 21,
    "start_time": "2022-01-01T08:09:45.149Z"
   },
   {
    "duration": 16,
    "start_time": "2022-01-01T08:10:29.378Z"
   },
   {
    "duration": 307,
    "start_time": "2022-01-01T08:10:33.390Z"
   },
   {
    "duration": 761,
    "start_time": "2022-01-01T08:19:54.992Z"
   },
   {
    "duration": 537,
    "start_time": "2022-01-01T08:21:04.617Z"
   },
   {
    "duration": 532,
    "start_time": "2022-01-01T08:21:21.330Z"
   },
   {
    "duration": 533,
    "start_time": "2022-01-01T08:21:53.506Z"
   },
   {
    "duration": 532,
    "start_time": "2022-01-01T08:23:04.916Z"
   },
   {
    "duration": 9466,
    "start_time": "2022-01-01T08:30:16.227Z"
   },
   {
    "duration": 6,
    "start_time": "2022-01-01T08:30:50.788Z"
   },
   {
    "duration": 497,
    "start_time": "2022-01-01T08:31:02.565Z"
   },
   {
    "duration": 389,
    "start_time": "2022-01-01T08:31:51.262Z"
   },
   {
    "duration": 517,
    "start_time": "2022-01-01T08:32:09.758Z"
   },
   {
    "duration": 515,
    "start_time": "2022-01-01T08:32:49.983Z"
   },
   {
    "duration": 420,
    "start_time": "2022-01-01T08:35:57.011Z"
   },
   {
    "duration": 1539,
    "start_time": "2022-01-01T08:47:29.642Z"
   },
   {
    "duration": 6488,
    "start_time": "2022-01-01T08:47:31.184Z"
   },
   {
    "duration": 11,
    "start_time": "2022-01-01T08:47:37.676Z"
   },
   {
    "duration": 144,
    "start_time": "2022-01-01T08:47:37.689Z"
   },
   {
    "duration": 169,
    "start_time": "2022-01-01T08:47:37.835Z"
   },
   {
    "duration": 113,
    "start_time": "2022-01-01T08:47:38.007Z"
   },
   {
    "duration": 98,
    "start_time": "2022-01-01T08:47:38.122Z"
   },
   {
    "duration": 96,
    "start_time": "2022-01-01T08:47:38.222Z"
   },
   {
    "duration": 41,
    "start_time": "2022-01-01T08:47:38.322Z"
   },
   {
    "duration": 11,
    "start_time": "2022-01-01T08:47:38.366Z"
   },
   {
    "duration": 81,
    "start_time": "2022-01-01T08:47:38.379Z"
   },
   {
    "duration": 15,
    "start_time": "2022-01-01T08:47:38.462Z"
   },
   {
    "duration": 5,
    "start_time": "2022-01-01T08:47:38.479Z"
   },
   {
    "duration": 37,
    "start_time": "2022-01-01T08:47:38.486Z"
   },
   {
    "duration": 59,
    "start_time": "2022-01-01T08:47:38.525Z"
   },
   {
    "duration": 17,
    "start_time": "2022-01-01T08:47:38.586Z"
   },
   {
    "duration": 22,
    "start_time": "2022-01-01T08:47:38.605Z"
   },
   {
    "duration": 22,
    "start_time": "2022-01-01T08:47:38.660Z"
   },
   {
    "duration": 17,
    "start_time": "2022-01-01T08:47:38.684Z"
   },
   {
    "duration": 17,
    "start_time": "2022-01-01T08:47:38.703Z"
   },
   {
    "duration": 43,
    "start_time": "2022-01-01T08:47:38.722Z"
   },
   {
    "duration": 20,
    "start_time": "2022-01-01T08:47:38.767Z"
   },
   {
    "duration": 8,
    "start_time": "2022-01-01T08:47:38.790Z"
   },
   {
    "duration": 875,
    "start_time": "2022-01-01T08:47:38.801Z"
   },
   {
    "duration": 573,
    "start_time": "2022-01-01T08:47:39.679Z"
   },
   {
    "duration": 22,
    "start_time": "2022-01-01T08:47:40.255Z"
   },
   {
    "duration": 337,
    "start_time": "2022-01-01T08:47:40.281Z"
   },
   {
    "duration": 367,
    "start_time": "2022-01-01T08:47:40.620Z"
   },
   {
    "duration": 1216,
    "start_time": "2022-01-01T12:08:54.942Z"
   },
   {
    "duration": 6473,
    "start_time": "2022-01-01T12:09:07.814Z"
   },
   {
    "duration": 8,
    "start_time": "2022-01-01T12:09:14.289Z"
   },
   {
    "duration": 87,
    "start_time": "2022-01-01T12:09:14.299Z"
   },
   {
    "duration": 99,
    "start_time": "2022-01-01T12:09:14.388Z"
   },
   {
    "duration": 80,
    "start_time": "2022-01-01T12:09:14.489Z"
   },
   {
    "duration": 44,
    "start_time": "2022-01-01T12:09:14.570Z"
   },
   {
    "duration": 41,
    "start_time": "2022-01-01T12:09:31.183Z"
   },
   {
    "duration": 14,
    "start_time": "2022-01-01T12:09:31.614Z"
   },
   {
    "duration": 8,
    "start_time": "2022-01-01T12:09:32.743Z"
   },
   {
    "duration": 40,
    "start_time": "2022-01-01T12:09:34.072Z"
   },
   {
    "duration": 12,
    "start_time": "2022-01-01T12:09:34.342Z"
   },
   {
    "duration": 5,
    "start_time": "2022-01-01T12:09:35.975Z"
   },
   {
    "duration": 24,
    "start_time": "2022-01-01T12:09:36.240Z"
   },
   {
    "duration": 22,
    "start_time": "2022-01-01T12:09:36.478Z"
   },
   {
    "duration": 13,
    "start_time": "2022-01-01T12:09:54.726Z"
   },
   {
    "duration": 16,
    "start_time": "2022-01-01T12:10:12.392Z"
   },
   {
    "duration": 15,
    "start_time": "2022-01-01T12:10:18.048Z"
   },
   {
    "duration": 11,
    "start_time": "2022-01-01T12:10:35.791Z"
   },
   {
    "duration": 13,
    "start_time": "2022-01-01T12:10:43.399Z"
   },
   {
    "duration": 12,
    "start_time": "2022-01-01T12:11:10.065Z"
   },
   {
    "duration": 15,
    "start_time": "2022-01-01T12:11:29.784Z"
   },
   {
    "duration": 6,
    "start_time": "2022-01-01T12:11:31.408Z"
   },
   {
    "duration": 577,
    "start_time": "2022-01-01T12:11:33.465Z"
   },
   {
    "duration": 345,
    "start_time": "2022-01-01T12:11:34.833Z"
   },
   {
    "duration": 5,
    "start_time": "2022-01-01T12:22:23.333Z"
   },
   {
    "duration": 308,
    "start_time": "2022-01-01T12:25:45.911Z"
   },
   {
    "duration": 354,
    "start_time": "2022-01-01T12:30:00.836Z"
   },
   {
    "duration": 400,
    "start_time": "2022-01-01T12:30:51.581Z"
   },
   {
    "duration": 19,
    "start_time": "2022-01-01T12:44:53.502Z"
   },
   {
    "duration": 13,
    "start_time": "2022-01-01T12:47:37.015Z"
   },
   {
    "duration": 4,
    "start_time": "2022-01-01T12:49:33.996Z"
   },
   {
    "duration": 4,
    "start_time": "2022-01-01T12:49:42.091Z"
   },
   {
    "duration": 5,
    "start_time": "2022-01-01T12:51:16.069Z"
   },
   {
    "duration": 19,
    "start_time": "2022-01-01T12:51:17.664Z"
   },
   {
    "duration": 87,
    "start_time": "2022-01-01T12:53:02.600Z"
   },
   {
    "duration": 79,
    "start_time": "2022-01-01T12:53:35.712Z"
   },
   {
    "duration": 8,
    "start_time": "2022-01-01T12:53:59.641Z"
   },
   {
    "duration": 8,
    "start_time": "2022-01-01T12:54:04.593Z"
   },
   {
    "duration": 11,
    "start_time": "2022-01-01T12:54:18.200Z"
   },
   {
    "duration": 17,
    "start_time": "2022-01-01T12:54:19.617Z"
   },
   {
    "duration": 338,
    "start_time": "2022-01-01T12:54:27.003Z"
   },
   {
    "duration": 8,
    "start_time": "2022-01-01T14:00:15.828Z"
   },
   {
    "duration": 30,
    "start_time": "2022-01-01T14:00:32.292Z"
   },
   {
    "duration": 10,
    "start_time": "2022-01-01T14:03:06.623Z"
   },
   {
    "duration": 260,
    "start_time": "2022-01-01T14:04:48.976Z"
   },
   {
    "duration": 29,
    "start_time": "2022-01-01T14:06:41.477Z"
   },
   {
    "duration": 5,
    "start_time": "2022-01-01T14:10:26.368Z"
   },
   {
    "duration": 5,
    "start_time": "2022-01-01T14:10:37.680Z"
   },
   {
    "duration": 42,
    "start_time": "2022-01-01T14:11:59.632Z"
   },
   {
    "duration": 7340,
    "start_time": "2022-01-01T14:14:25.132Z"
   },
   {
    "duration": 259,
    "start_time": "2022-01-01T14:15:17.628Z"
   },
   {
    "duration": 254,
    "start_time": "2022-01-01T14:16:30.790Z"
   },
   {
    "duration": 42,
    "start_time": "2022-01-01T14:16:45.509Z"
   },
   {
    "duration": 36,
    "start_time": "2022-01-01T14:17:25.023Z"
   },
   {
    "duration": 12,
    "start_time": "2022-01-01T14:18:13.120Z"
   },
   {
    "duration": 33,
    "start_time": "2022-01-01T14:23:45.463Z"
   },
   {
    "duration": 14,
    "start_time": "2022-01-01T14:24:00.053Z"
   },
   {
    "duration": 508,
    "start_time": "2022-01-01T14:27:03.272Z"
   },
   {
    "duration": 5,
    "start_time": "2022-01-01T14:27:53.594Z"
   },
   {
    "duration": 32,
    "start_time": "2022-01-01T14:27:59.619Z"
   },
   {
    "duration": 506,
    "start_time": "2022-01-01T14:28:07.036Z"
   },
   {
    "duration": 12,
    "start_time": "2022-01-01T14:28:25.766Z"
   },
   {
    "duration": 15,
    "start_time": "2022-01-01T14:29:34.851Z"
   },
   {
    "duration": 9,
    "start_time": "2022-01-01T14:29:52.069Z"
   },
   {
    "duration": 14,
    "start_time": "2022-01-01T14:30:05.333Z"
   },
   {
    "duration": 252,
    "start_time": "2022-01-01T14:33:10.776Z"
   },
   {
    "duration": 30,
    "start_time": "2022-01-01T14:33:20.625Z"
   },
   {
    "duration": 257,
    "start_time": "2022-01-01T14:33:21.112Z"
   },
   {
    "duration": 607,
    "start_time": "2022-01-01T14:33:36.968Z"
   },
   {
    "duration": 14,
    "start_time": "2022-01-01T14:33:44.585Z"
   },
   {
    "duration": 1222,
    "start_time": "2022-01-01T16:45:08.734Z"
   },
   {
    "duration": 1476,
    "start_time": "2022-01-02T07:26:41.454Z"
   },
   {
    "duration": 6696,
    "start_time": "2022-01-02T07:26:42.933Z"
   },
   {
    "duration": 10,
    "start_time": "2022-01-02T07:26:49.632Z"
   },
   {
    "duration": 152,
    "start_time": "2022-01-02T07:26:49.645Z"
   },
   {
    "duration": 183,
    "start_time": "2022-01-02T07:26:49.799Z"
   },
   {
    "duration": 136,
    "start_time": "2022-01-02T07:26:49.984Z"
   },
   {
    "duration": 97,
    "start_time": "2022-01-02T07:26:50.123Z"
   },
   {
    "duration": 61,
    "start_time": "2022-01-02T07:26:55.795Z"
   },
   {
    "duration": 15,
    "start_time": "2022-01-02T07:26:57.730Z"
   },
   {
    "duration": 9,
    "start_time": "2022-01-02T07:26:57.747Z"
   },
   {
    "duration": 74,
    "start_time": "2022-01-02T07:26:57.759Z"
   },
   {
    "duration": 14,
    "start_time": "2022-01-02T07:26:57.841Z"
   },
   {
    "duration": 7,
    "start_time": "2022-01-02T07:26:58.370Z"
   },
   {
    "duration": 37,
    "start_time": "2022-01-02T07:26:58.826Z"
   },
   {
    "duration": 33,
    "start_time": "2022-01-02T07:26:59.506Z"
   },
   {
    "duration": 19,
    "start_time": "2022-01-02T07:27:01.162Z"
   },
   {
    "duration": 22,
    "start_time": "2022-01-02T07:27:02.850Z"
   },
   {
    "duration": 22,
    "start_time": "2022-01-02T07:27:03.608Z"
   },
   {
    "duration": 416,
    "start_time": "2022-01-02T07:27:05.809Z"
   },
   {
    "duration": 275,
    "start_time": "2022-01-02T07:27:06.603Z"
   },
   {
    "duration": 273,
    "start_time": "2022-01-02T07:27:18.114Z"
   },
   {
    "duration": 301,
    "start_time": "2022-01-02T07:27:18.676Z"
   },
   {
    "duration": 8,
    "start_time": "2022-01-02T07:27:20.699Z"
   },
   {
    "duration": 844,
    "start_time": "2022-01-02T07:27:22.194Z"
   },
   {
    "duration": 565,
    "start_time": "2022-01-02T07:27:24.609Z"
   },
   {
    "duration": 565,
    "start_time": "2022-01-02T07:27:26.515Z"
   },
   {
    "duration": 321,
    "start_time": "2022-01-02T07:27:28.848Z"
   },
   {
    "duration": 316,
    "start_time": "2022-01-02T07:27:29.265Z"
   },
   {
    "duration": 133,
    "start_time": "2022-01-02T07:27:32.052Z"
   },
   {
    "duration": 281,
    "start_time": "2022-01-02T07:27:32.858Z"
   },
   {
    "duration": 336,
    "start_time": "2022-01-02T07:27:33.490Z"
   },
   {
    "duration": 348,
    "start_time": "2022-01-02T07:27:49.547Z"
   },
   {
    "duration": 356,
    "start_time": "2022-01-02T07:27:50.074Z"
   },
   {
    "duration": 432,
    "start_time": "2022-01-02T07:27:51.146Z"
   },
   {
    "duration": 283,
    "start_time": "2022-01-02T07:28:06.251Z"
   },
   {
    "duration": 14,
    "start_time": "2022-01-02T07:28:25.548Z"
   },
   {
    "duration": 43,
    "start_time": "2022-01-02T07:28:33.900Z"
   },
   {
    "duration": 15,
    "start_time": "2022-01-02T07:34:53.720Z"
   },
   {
    "duration": 7,
    "start_time": "2022-01-02T07:34:58.622Z"
   },
   {
    "duration": 45,
    "start_time": "2022-01-02T07:35:04.256Z"
   },
   {
    "duration": 45,
    "start_time": "2022-01-02T07:35:28.496Z"
   },
   {
    "duration": 30,
    "start_time": "2022-01-02T07:36:01.297Z"
   },
   {
    "duration": 11,
    "start_time": "2022-01-02T07:39:47.594Z"
   },
   {
    "duration": 16,
    "start_time": "2022-01-02T07:54:17.048Z"
   },
   {
    "duration": 11,
    "start_time": "2022-01-02T07:54:17.475Z"
   },
   {
    "duration": 157,
    "start_time": "2022-01-02T07:54:18.507Z"
   },
   {
    "duration": 29,
    "start_time": "2022-01-02T07:54:32.426Z"
   },
   {
    "duration": 34,
    "start_time": "2022-01-02T07:54:49.195Z"
   },
   {
    "duration": 26,
    "start_time": "2022-01-02T07:55:12.371Z"
   },
   {
    "duration": 16,
    "start_time": "2022-01-02T07:55:53.964Z"
   },
   {
    "duration": 28,
    "start_time": "2022-01-02T07:56:13.517Z"
   },
   {
    "duration": 26,
    "start_time": "2022-01-02T07:56:43.460Z"
   },
   {
    "duration": 14,
    "start_time": "2022-01-02T07:56:52.532Z"
   },
   {
    "duration": 155,
    "start_time": "2022-01-02T07:58:21.359Z"
   },
   {
    "duration": 26,
    "start_time": "2022-01-02T07:58:35.035Z"
   },
   {
    "duration": 27,
    "start_time": "2022-01-02T08:00:56.967Z"
   },
   {
    "duration": 1661,
    "start_time": "2022-01-02T12:34:43.230Z"
   },
   {
    "duration": 6827,
    "start_time": "2022-01-02T12:34:45.863Z"
   },
   {
    "duration": 10,
    "start_time": "2022-01-02T12:34:55.225Z"
   },
   {
    "duration": 123,
    "start_time": "2022-01-02T12:34:55.533Z"
   },
   {
    "duration": 136,
    "start_time": "2022-01-02T12:34:55.799Z"
   },
   {
    "duration": 79,
    "start_time": "2022-01-02T12:34:55.983Z"
   },
   {
    "duration": 110,
    "start_time": "2022-01-02T12:34:56.184Z"
   },
   {
    "duration": 62,
    "start_time": "2022-01-02T12:34:57.326Z"
   },
   {
    "duration": 15,
    "start_time": "2022-01-02T12:34:57.518Z"
   },
   {
    "duration": 9,
    "start_time": "2022-01-02T12:34:58.126Z"
   },
   {
    "duration": 58,
    "start_time": "2022-01-02T12:34:59.384Z"
   },
   {
    "duration": 15,
    "start_time": "2022-01-02T12:34:59.878Z"
   },
   {
    "duration": 6,
    "start_time": "2022-01-02T12:35:01.406Z"
   },
   {
    "duration": 39,
    "start_time": "2022-01-02T12:35:01.630Z"
   },
   {
    "duration": 34,
    "start_time": "2022-01-02T12:35:01.831Z"
   },
   {
    "duration": 19,
    "start_time": "2022-01-02T12:35:02.254Z"
   },
   {
    "duration": 23,
    "start_time": "2022-01-02T12:35:03.326Z"
   },
   {
    "duration": 21,
    "start_time": "2022-01-02T12:35:03.526Z"
   },
   {
    "duration": 425,
    "start_time": "2022-01-02T12:35:04.294Z"
   },
   {
    "duration": 283,
    "start_time": "2022-01-02T12:35:04.959Z"
   },
   {
    "duration": 286,
    "start_time": "2022-01-02T12:35:05.830Z"
   },
   {
    "duration": 303,
    "start_time": "2022-01-02T12:35:06.503Z"
   },
   {
    "duration": 7,
    "start_time": "2022-01-02T12:35:06.969Z"
   },
   {
    "duration": 959,
    "start_time": "2022-01-02T12:35:07.670Z"
   },
   {
    "duration": 576,
    "start_time": "2022-01-02T12:35:08.631Z"
   },
   {
    "duration": 618,
    "start_time": "2022-01-02T12:35:09.209Z"
   },
   {
    "duration": 307,
    "start_time": "2022-01-02T12:35:14.479Z"
   },
   {
    "duration": 1211,
    "start_time": "2022-01-02T12:35:13.577Z"
   },
   {
    "duration": 56,
    "start_time": "2022-01-02T12:35:15.481Z"
   },
   {
    "duration": 316,
    "start_time": "2022-01-02T12:35:15.695Z"
   },
   {
    "duration": 1198,
    "start_time": "2022-01-02T12:35:14.815Z"
   },
   {
    "duration": 359,
    "start_time": "2022-01-02T12:35:17.544Z"
   },
   {
    "duration": 372,
    "start_time": "2022-01-02T12:35:18.919Z"
   },
   {
    "duration": 436,
    "start_time": "2022-01-02T12:35:20.087Z"
   },
   {
    "duration": 14,
    "start_time": "2022-01-02T12:35:28.230Z"
   },
   {
    "duration": 12,
    "start_time": "2022-01-02T12:35:28.895Z"
   },
   {
    "duration": 158,
    "start_time": "2022-01-02T12:35:29.817Z"
   },
   {
    "duration": 8,
    "start_time": "2022-01-02T12:35:42.760Z"
   },
   {
    "duration": 278,
    "start_time": "2022-01-02T12:35:46.166Z"
   },
   {
    "duration": 6,
    "start_time": "2022-01-02T12:37:37.369Z"
   },
   {
    "duration": 28,
    "start_time": "2022-01-02T12:38:03.234Z"
   },
   {
    "duration": 13,
    "start_time": "2022-01-02T12:39:00.894Z"
   },
   {
    "duration": 5,
    "start_time": "2022-01-02T12:39:08.907Z"
   },
   {
    "duration": 26,
    "start_time": "2022-01-02T12:39:09.411Z"
   },
   {
    "duration": 416,
    "start_time": "2022-01-02T12:44:56.383Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
